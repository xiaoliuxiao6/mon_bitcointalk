#!/usr/bin/env python3
"""
btt-altcoin-scraper.py â€” BitcoinTalk å±±å¯¨å¸å…¬å‘ŠåŒºæŠ“å–å™¨
æŠ“å– board=159 (Announcements - Altcoins) æœ€æ–°å‘å¸ƒçš„å¸–å­ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼‰

ç”¨æ³•:
  python3 btt-altcoin-scraper.py                  # æŠ“æœ€æ–°å‘å¸ƒçš„ 10 ä¸ªå¸–å­
  python3 btt-altcoin-scraper.py --count 20       # æŠ“ 20 ä¸ª
  python3 btt-altcoin-scraper.py --json            # è¾“å‡º JSON
  python3 btt-altcoin-scraper.py --output result.json  # ä¿å­˜åˆ°æ–‡ä»¶
  python3 btt-altcoin-scraper.py --mining          # åªæ˜¾ç¤ºæŒ–çŸ¿ç›¸å…³å¸–å­

ä¾èµ–: ä»… Python 3 æ ‡å‡†åº“ï¼Œæ— éœ€å®‰è£…ä»»ä½•ç¬¬ä¸‰æ–¹åŒ…

å®šæ—¶è¿è¡Œ:
  crontab -e
  0 */6 * * * /usr/bin/python3 /path/to/btt-altcoin-scraper.py --json --output /path/to/btt_latest.json
"""
import argparse, json, logging, os, re, sys, time, urllib.request
from datetime import datetime, timezone, timedelta

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—ï¼ˆsort=first_post;descï¼‰
BOARD_URL = "https://bitcointalk.org/index.php?board=159.0;sort=first_post;desc"
USER_AGENT = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"

# Discord Webhookï¼ˆä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæœ¬åœ°å¼€å‘å¯ç¡¬ç¼–ç ï¼‰
DISCORD_WEBHOOK_URL = os.environ.get(
    "DISCORD_WEBHOOK_URL",
    "https://discord.com/api/webhooks/1476878218886905898/dZgrA3Srpj1pmFOlMr8QcIjAE_Ls4DJuMaLjNSpW7wtxeb0E-dJmosVGaOrXpOYoL4pt"
)

# ç»“æœæ–‡ä»¶ï¼ˆç”¨äºå»é‡ï¼‰
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
RESULT_FILE = os.path.join(SCRIPT_DIR, "jieguo.json")

# å®šæ—¶é—´éš”ï¼ˆç§’ï¼‰
INTERVAL = 10 * 60

# æŒ–çŸ¿å…³é”®è¯
MINING_RE = re.compile(
    r"\bpow\b|\bPoW\b|proof.of.work|mining|miner|hashrate|hash.rate"
    r"|cpu.min|gpu.min|asic.resist|fair.launch|no.premine|block.reward"
    r"|mineable|mine?able"
    r"|RandomX|KawPow|ProgPoW|Equihash|Autolykos|kHeavyHash|CryptoNight"
    r"|MinotaurX|Verthash|FishHash|zkPoW|BeamHash|YesPoWer|SpectreX"
    r"|Ethash|\bScrypt\b|SHA.?256d?|Cuckoo|Blake3|Keccak.?256|Argon2"
    r"|stratum|solo.min|pool.min",
    re.IGNORECASE,
)
# æ’é™¤è¯¯åˆ¤
MINING_EXCLUDE = re.compile(
    r"trading|bot|assistant|DeFi|swap|lending|staking|NFT|token sale"
    r"|presale|IDO|IEO|launchpad|airdrop|generosity|charity",
    re.IGNORECASE,
)


def fetch_page(url: str) -> str:
    """æŠ“å–é¡µé¢ HTML"""
    req = urllib.request.Request(url, headers={"User-Agent": USER_AGENT})
    with urllib.request.urlopen(req, timeout=30) as resp:
        return resp.read().decode("iso-8859-1", errors="replace")


def parse_posts(html: str) -> list[dict]:
    """ç”¨æ­£åˆ™è§£æå¸–å­åˆ—è¡¨ï¼ˆæ¯” HTMLParser æ›´å¯é ï¼‰"""
    posts = []

    # æå–æ‰€æœ‰å¸–å­è¡Œï¼šmsg_ID å¼€å¤´çš„ span åŒ…å«æ ‡é¢˜å’Œé“¾æ¥
    # æ ¼å¼: <span id="msg_XXXXX"><a href="...topic=NNNNN.0">æ ‡é¢˜</a></span>
    pattern = re.compile(
        r'<span\s+id="msg_(\d+)">'
        r'\s*<a\s+href="(https://bitcointalk\.org/index\.php\?topic=(\d+)\.\d+)">'
        r'(.+?)</a>\s*</span>',
        re.DOTALL,
    )

    matches = list(pattern.finditer(html))

    # æå–ç½®é¡¶å¸–çš„ topic IDï¼ˆé€šè¿‡ stickyicon å›¾ç‰‡è¯†åˆ«ï¼‰
    sticky_pattern = re.compile(r'id="stickyicon_(\d+)"')
    sticky_topics = set()
    for m in sticky_pattern.finditer(html):
        sticky_topics.add(m.group(1))

    # æå–æ¯ä¸ªå¸–å­çš„ä½œè€…ã€å›å¤æ•°ã€æµè§ˆæ•°
    # å¸–å­è¡Œç»“æ„ï¼šåœ¨ msg_XXX ä¹‹åï¼ŒåŒä¸€ä¸ª tr é‡Œæœ‰ä½œè€…ã€å›å¤ã€æµè§ˆ
    # ç”¨ topic ID å…³è”

    # æå–ä½œè€…ï¼šç´§è·Ÿåœ¨å¸–å­æ ‡é¢˜åé¢çš„ profile é“¾æ¥
    author_pattern = re.compile(
        r'topic=(\d+)\.\d+">.*?</a>.*?'
        r'action=profile[^"]*">([^<]+)</a>',
        re.DOTALL,
    )
    authors = {}
    for m in author_pattern.finditer(html):
        authors[m.group(1)] = m.group(2).strip()

    # æå–å›å¤æ•°å’Œæµè§ˆæ•°ï¼šåœ¨ td class="stickybg2" æˆ– "windowbg2" ä¸­
    # ç®€åŒ–æ–¹æ¡ˆï¼šç”¨ topic é¡ºåºå¯¹åº”
    stats_pattern = re.compile(
        r'<td\s+class="(?:stickybg2|windowbg2|stickybg|windowbg)"\s+'
        r'(?:style="[^"]*"\s+)?'
        r'(?:width="[^"]*"\s+)?'
        r'[^>]*>\s*(\d+)\s*</td>',
    )

    for m in matches:
        msg_id = m.group(1)
        url = m.group(2)
        topic_id = m.group(3)
        title = m.group(4).strip()

        # æ¸…ç† HTML å®ä½“
        title = title.replace("&amp;", "&").replace("&lt;", "<").replace("&gt;", ">")
        title = title.replace("&#039;", "'").replace("&quot;", '"')
        # è§£ç æ•°å­— HTML å®ä½“ï¼ˆå¦‚ &#128293; -> ğŸ”¥ï¼‰
        title = re.sub(r'&#(\d+);', lambda m: chr(int(m.group(1))), title)
        title = re.sub(r'<[^>]+>', '', title)  # å»æ‰æ®‹ç•™ HTML æ ‡ç­¾

        # è·³è¿‡ç½®é¡¶å¸–
        if topic_id in sticky_topics:
            continue

        # è·³è¿‡ç‰ˆè§„å¸–ï¼ˆmsg_id å¾ˆå°çš„é€šå¸¸æ˜¯ç‰ˆè§„ï¼‰
        if int(msg_id) < 20000000:
            continue

        # è·³è¿‡éå¸¸æ—§çš„å¸–å­ï¼ˆtopic_id å¾ˆå°è¯´æ˜åˆ›å»ºæ—¶é—´å¾ˆæ—©ï¼‰
        if int(topic_id) < 5500000:
            continue

        post = {
            "topic_id": int(topic_id),
            "msg_id": int(msg_id),
            "title": title,
            "url": url,
            "author": authors.get(topic_id, ""),
        }
        posts.append(post)

    # æŒ‰ topic_id å€’åºï¼ˆæœ€æ–°åˆ›å»ºçš„åœ¨å‰ï¼‰
    posts.sort(key=lambda x: x["topic_id"], reverse=True)

    return posts


def is_mining_related(post: dict) -> bool:
    """åˆ¤æ–­å¸–å­æ˜¯å¦ä¸æŒ–çŸ¿ç›¸å…³"""
    title = post.get("title", "")
    if MINING_EXCLUDE.search(title):
        return False
    return bool(MINING_RE.search(title))


def load_seen_topics() -> dict:
    """ä» jieguo.json åŠ è½½å·²è®°å½•çš„å¸–å­ï¼Œè¿”å› {topic_id: record}"""
    if os.path.exists(RESULT_FILE):
        try:
            with open(RESULT_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return {item['topic_id']: item for item in data}
        except (json.JSONDecodeError, KeyError):
            logger.warning(f"jieguo.json æ ¼å¼å¼‚å¸¸ï¼Œå°†é‡æ–°åˆ›å»º")
    return {}


def save_seen_topics(seen: dict):
    """å°†å·²è®°å½•å¸–å­å†™å› jieguo.json"""
    data = sorted(seen.values(), key=lambda x: x['topic_id'], reverse=True)
    with open(RESULT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def send_discord_notification(post: dict):
    """å‘é€ Discord Webhook é€šçŸ¥"""
    mining_tag = " â›ï¸" if post.get("is_mining") else ""
    text = (
        f"\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"ğŸ†• **New Post / æ–°å¸–å‘å¸ƒ**{mining_tag}\n\n"
        f"> ğŸ“Œ **{post['title']}**\n"
        f"> \n"
        f"> ğŸ‘¤ Author / ä½œè€…: **{post.get('author', 'N/A')}**\n"
        f"> ğŸ• Time / æ—¶é—´: {post.get('found_at', 'N/A')}\n"
        f"> ğŸ”— <{post['url']}>\n"
        f"\n"
    )
    message = {"content": text}
    data = json.dumps(message).encode('utf-8')
    req = urllib.request.Request(
        DISCORD_WEBHOOK_URL,
        data=data,
        headers={
            "Content-Type": "application/json",
            "User-Agent": "Mozilla/5.0",
        },
        method="POST",
    )
    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            if resp.status == 204:
                logger.info(f"âœ… Discord é€šçŸ¥å·²å‘é€: {post['title']}")
            else:
                logger.warning(f"âš ï¸ Discord è¿”å› HTTP {resp.status}")
    except Exception as e:
        logger.error(f"âŒ Discord é€šçŸ¥å¤±è´¥: {e}")


def run_once() -> int:
    """æ‰§è¡Œä¸€æ¬¡æŠ“å–ï¼Œè¿”å›æ–°å‘ç°çš„å¸–å­æ•°é‡"""
    logger.info("å¼€å§‹æŠ“å–...")
    try:
        html = fetch_page(BOARD_URL)
    except Exception as e:
        logger.error(f"æŠ“å–é¡µé¢å¤±è´¥: {e}")
        return 0

    posts = parse_posts(html)
    logger.info(f"è§£æåˆ° {len(posts)} ä¸ªå¸–å­ï¼ˆå·²æ’é™¤ç½®é¡¶/ç‰ˆè§„ï¼‰")

    seen = load_seen_topics()
    new_count = 0

    for post in posts:
        topic_id = post['topic_id']
        if topic_id in seen:
            continue

        # æ–°å¸–å­
        post['is_mining'] = is_mining_related(post)
        post['found_at'] = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M:%S")
        seen[topic_id] = post
        new_count += 1

        logger.info(f"ğŸ†• æ–°å¸–: {post['title']} (topic={topic_id})")
        send_discord_notification(post)
        # é¿å…è§¦å‘ Discord rate limit
        time.sleep(1)

    save_seen_topics(seen)
    logger.info(f"æœ¬è½®å®Œæˆ: {new_count} æ¡æ–°å¸–, æ€»è®°å½• {len(seen)} æ¡")
    return new_count


def run_loop():
    """å®šæ—¶å¾ªç¯è¿è¡Œï¼Œæ¯ 10 åˆ†é’Ÿä¸€æ¬¡"""
    logger.info(f"å¯åŠ¨å®šæ—¶æ¨¡å¼ï¼Œæ¯ {INTERVAL // 60} åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ (Ctrl+C åœæ­¢)")
    while True:
        try:
            run_once()
        except Exception as e:
            logger.error(f"è¿è¡Œå¼‚å¸¸: {e}")
        logger.info(f"ç­‰å¾… {INTERVAL // 60} åˆ†é’Ÿåå†æ¬¡è¿è¡Œ...")
        time.sleep(INTERVAL)


def main():
    parser = argparse.ArgumentParser(description="BitcoinTalk Altcoin ANN Scraper")
    parser.add_argument("--loop", action="store_true", help="å®šæ—¶å¾ªç¯æ¨¡å¼ï¼ˆæ¯10åˆ†é’Ÿä¸€æ¬¡ï¼‰")
    parser.add_argument("--once", action="store_true", help="è¿è¡Œä¸€æ¬¡ï¼ˆæŠ“å–+å»é‡+é€šçŸ¥ï¼‰")
    parser.add_argument("--count", type=int, default=10, help="æŠ“å–æ•°é‡ (é»˜è®¤ 10)")
    parser.add_argument("--json", action="store_true", help="è¾“å‡º JSON æ ¼å¼")
    parser.add_argument("--output", type=str, help="ä¿å­˜åˆ°æ–‡ä»¶")
    parser.add_argument("--mining", action="store_true", help="åªæ˜¾ç¤ºæŒ–çŸ¿ç›¸å…³å¸–å­")
    args = parser.parse_args()

    # å®šæ—¶å¾ªç¯æ¨¡å¼
    if args.loop:
        run_loop()
        return

    # å•æ¬¡è¿è¡Œæ¨¡å¼ï¼ˆæŠ“å– + å»é‡ + Discord é€šçŸ¥ï¼‰
    if args.once:
        run_once()
        return

    # ä»¥ä¸‹ä¸ºåŸå§‹æŸ¥çœ‹æ¨¡å¼ï¼ˆä¸ä¿å­˜ã€ä¸é€šçŸ¥ï¼‰
    html = fetch_page(BOARD_URL)
    posts = parse_posts(html)

    if args.mining:
        posts = [p for p in posts if is_mining_related(p)]

    posts = posts[:args.count]

    for p in posts:
        p["is_mining"] = is_mining_related(p)

    if args.json or args.output:
        result = {
            "scraped_at": datetime.now(tz=timezone.utc).isoformat(),
            "board": "Announcements (Altcoins)",
            "board_url": BOARD_URL,
            "sort": "newest_first",
            "count": len(posts),
            "mining_only": args.mining,
            "posts": posts,
        }
        json_str = json.dumps(result, indent=2, ensure_ascii=False)

        if args.output:
            with open(args.output, "w", encoding="utf-8") as f:
                f.write(json_str)
            print(f"âœ… å·²ä¿å­˜åˆ° {args.output} ({len(posts)} æ¡)")
        else:
            print(json_str)
    else:
        print(f"\nğŸ“‹ BitcoinTalk å±±å¯¨å¸å…¬å‘ŠåŒº â€” æœ€æ–°å‘å¸ƒ {len(posts)} æ¡")
        print(f"   æ’åº: æŒ‰åˆ›å»ºæ—¶é—´ï¼ˆæœ€æ–°åœ¨å‰ï¼‰")
        if args.mining:
            print(f"   è¿‡æ»¤: ä»…æŒ–çŸ¿ç›¸å…³")
        print("=" * 70)
        for i, p in enumerate(posts, 1):
            mining_tag = " â›ï¸" if p["is_mining"] else ""
            print(f"\n[{i:2d}] {p['title']}{mining_tag}")
            print(f"     ä½œè€…: {p['author']}  |  Topic ID: {p['topic_id']}")
            print(f"     {p['url']}")
        print(f"\n{'='*70}")


if __name__ == "__main__":
    main()
